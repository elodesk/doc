\chapter{Introduction to Data Streaming}

The view of data as rows of databases or single files changes when one thinks
about what a business actually does with the generated data. Where retail
generates orders they lead to sales, shipments and so on, a financial institution will
generate orders they are going to have an impact of a stock price. Or a social
network platform generates clicks, impressions and searches they are used to
make some sort of intelligent analysis to further display personalized data to
it's users. Such kind of data can be thought of as streams of events. In fact,
collecting all events a business ever generated will lead to the current state
of the business and thus describe what the business did in past. For example the
current price of a stock was generated by all the orders ever made on this
stock. Every order can be captured as an event and so can all events together reproduce
the current stock price.

\section{Processing of events}

The data stream consisting of continuous events as it self is not valueable but
can be taken advantage of by a system that processes the events and produces a
result. This can be the calculation of the new stock price after a customer sold
his stock or the personalized content on my news feed after I subscribed to a new fan
page. But it could also be a more complex analysis over all the collected user
data.
\\ \\
In fact, the above mentioned examples differ in it's nature. Where the
calculation of the stock price is fairly simple by setting the price to the
latest paid stock price, whithout any knowledge about the stock prices in past. 
In contrast, a complete analysis over a huge user base will not only require a
significant amount of processing time, it also requires some data produced in the
past. We distinguish between stream processing for the first and batch
processing for the latter.

\section{Stream Processing}

Stream processing refers to processing of data before storing. 
A stream processing system is built out of multiple units called a processing
element (PE). Each PE receive input from their input queues, does some
computation on the input using its local state and produce output to their
output queues. PE communicate always through messaging with other PEs. 
\\
Most important, those systems are optimized for high latency and high
availability. Recovering from failures is critical for a stream processing
systems and should be fast and efficient. 
Data should partitioned and handled in parallel for large volumes of data. 
The partitioning strategy of a system  affects how the system
handles the data in parallel and how the system can scale. 

\todo[inline]{source?}


\section{Complex event processing (CEP)}
In literatur there is often a confusion about the difference between the terms
complex event processing and stream event processing. Both systems work on
events and produce results based on the properties of the events... 
- Zitat: Combines data from multiple sources  to detect patterns and attempt to
identify either opportunities or threats. The goal is to identify significant
events and respond fast. Sales leads, orders or customer service calls are
examples.\\


\section{Real-time versus Batch Processing}

As the trend shows, the needs of a big data environment can't be fulfilled with 
traditional batch processing anymore. Instead, real-time processing becomes more 
important than ever to achieve results from queries in minutes, even seconds. 
\cite{bange2013big}

\todo[inline]{LW: Mir fehlt irgendwie noch die ErklÃ¤rung was traditional batch
processing ist und warum es den heutigen anforderungen nicht mehr gerecht
werden kann (eingesetzt wird es ja nach wie vor) }

Traditional batch processing systems nowadays are distinguished between
map-reduce based and non map-reduce based systems and typically consists of two
stages, data integration and data analytics. The process of data
extraction-transformation-load (ETL  [glossar]), faced in the data integration
stage, runs at a regular time interval, such as daily, weekly or monthly. The
process, which analyzes the data residing in a data store is being faced in the
data analytics stage and becomes challenging when data size grows and systems
may not be able to process results within a time limit.
\cite{Liu:2014:SRP:2628194.2628251}

In real-time processing fashion, systems will address the data integration stage
with continual input of data. Processing in near-real-time [glossar] to present 
results within seconds is being addressed in the data analytics stage. Thus,
real-time processing gives organization the ability to take immediate action
for those times when acting within seconds or minutes is significant.
\cite{PrpSvyOfDSPS}

\todo[inline]{LW: Rein vom Text habe ich das mit den Stages irgendwie nicht ganz
verstanden. Du schreibst batch processing beinhaltet diese beiden Stages. Aber
Real-time scheinbar auch? Sind das die gleichen Stages?  }


\section{Lambda Architecture}
The lambda architecture introduces a new paradigm for big data which allows
processing of massive data volumes in near real-time fashion and thus results within
seconds can be achieved. 
\\
Any query is answered through the serving layer by querying 
both the speed and the batch layer. Where the badge layer computes views on the current collected data and
is being outdated at the end of it's computation, the speed layer closes this 
gap by constantly processing the most recent data in near real-time fashion. 
\cite{marz2015big} \cite{PrpSvyOfDSPS}

\section{Stream Sources}
Every system that is dependent on a continuous input of data requires a data
source that actually delivers data constantly to it's consumers. Such systems
can be found in any speed- or batch layer of a lambda architecture environment. 
But also a lot of more traditionally built business intelligence systems have to be
served with data continuously.

\section{Stream Broker}


- problem of traditional messaging systems
- point to the need of data stream broker systems

%todo: point to the need of messaging systems that deliver data continously ->
%stream source 

-From traditional PCs and Smartphones to a lot of sensors who are connected to
the interne -> Internet of Things!



