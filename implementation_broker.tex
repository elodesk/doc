\chapter{Implementation Broker}
\label{chap:broker}
The broker implementation is a stand-alone server application which is based on the
Apache Kafka protocol implementation (see \ref{sec-protocol}). To clarify the
program flow from receiving data from network to handling the requests and
accessing the message log, the broker is split into three
layers, each in its own module. 

\begin{description}
    \item [Network Layer] \hfill \\
        This modules encapsulate action on the network. It initiates
        connections and receive bytes from client. It chunks the received bytes
        into single requests and provide it to the API Layer. 
    \item [API Layer] \hfill \\
        This module handles incoming requests. First of all it parses the
        received bytes as RequestMessage and proceeds an appropriate action
        depending on the delivered API key. After performing the action, an
        according ResponseMessage is generated and provided to the Network Layer
        for sending back to the client. 
    \item [Log Layer] \hfill \\
        This module encapsulates actions to the log on the filesystem.
        Fundamental functions are appending MessageSet's to Log or reading from
        it. 
\end{description}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{images/impl-brok-layers.png}
    \caption{Three subsystems of broker server application}
    \label{fig:impl-brok-layers}
\end{figure}




\section{Network Layer}
\label{sec:broker-network}

The broker application has a thin network layer which is responsible for
receiving and sending binary data to clients. Instead of using HTTP, 
connection-oriented sockets (TCP) are used. The broker is therefore independent
of any HTTP implementation and clients can make use of some of the more advanced
TCP features like the ability to simultaneously poll many connections or to
multiplex requests. While a socket is an endpoint of a bidirectional
inter-process communication flow, each connection established to the broker is
basically a socket connection. That being said, it is important to provide a
reliable socket server implementation which will serve correctly under a heavy
load. Haskell provides full control over sockets using the
\fnurl{Network.Socket}{https://hackage.haskell.org/package/network-2.3.0.7/docs/Network-Socket.html}
module which exposes the \fnurl{C socket
API}{http://pubs.opengroup.org/onlinepubs/7908799/xns/syssocket.h.html}.

This section shows the basic operations and describes the used libraries in the
network layer. For further details about the threading concept see section
\ref{sec:impl-broker-threading} 

\subsection{Socket connection establishment}
\label{sec:impl-broker-socket-connection}
%The following figure (\ref{fig:broker-activity}) shows the abstract view of how
%the socket connection between a client and the broker establishes so that a
%communication between those two counterparts can proceed.

%\begin{figure}[H]
%    \centering
%    \includegraphics[width=0.7\textwidth]{images/broker-activity.png}
%    \caption{Broker request handling concept}
%    \label{fig:broker-activity}
%\end{figure}

\subsubsection{Initialize Socket}

First of all, the initialization process of a socket happens on the server by providing the following configuration parameters:
\begin{description}
  \item[Protocol Family] \textit{AF\_INET}, for network protocol IPv4
  \item[Socket Type] \textit{Stream}, which provides sequenced, reliable, two-way, connection-based byte streams.
  \item[Protocol Number] \textit{0}, which indicates that the caller does not want to specify the protocol and will leave it up to the service provider.
\end{description}

\subsubsection{Bind Socket}

After the configuration is set, the socket has to be associated with an address
structure which is a constellation of an IP Address and Port. The constructor
\textit{SockAddrInet} of the data type \textit{SockAddr} takes the following
two arguments:

\begin{description}
  \item[Port Number] 4343
  \item[Host Address] iNADDR\_ANY, which binds the socket to all interfaces
\end{description}

TODO: static but could be done with dynamic configuration

\subsubsection{Listen}

While the socket is created and bound to an interface, the socket state can be
entered into listening state. The only configuration parameter which has to be
considered is the maximum number of queued connections they are requesting to
be accepted -- also called backlog. While this parameter is not critical in the
constellation of this broker, we set the queue length to \textbf{50}, which is
also the default value in the Java SocketServer implementation. \textit{Note,
that the focus remains on the amount of data being processed rather than the
number of clients being served.}

\subsection{Receive data}
\label{sec:impl-broker-socket-receive}
To receive data from socket buffer we use the function recv from
\fnurl{Network.Socket.ByteString.Lazy}{https://hackage.haskell.org/package/network-2.3.0.1/docs/Network-Socket-ByteString-Lazy.html}
library which provides access to the Unix socket interface. Because we work
with a binary protocol and need to parse the data from binary data directly,
this module is much more efficient than the string based network functions. We
take the lazy variant of the library because the input gets directly parsed by
our lazy based encoder \todo{ref}.

Because we want to handle each request individually we explicitly read
only the exact amount of bytes which is needed get one particular request from
the socket buffer. To get the size of a whole request we read the first four
bytes which determines the request size according to the protocol and parse it
to an numeral value.

\begin{lstlisting}
import qualified Network.Socket.ByteString.Lazy as S 
import qualified Data.ByteString.Lazy as BL

recvFromSock :: (Socket, SockAddr) -> IO BL.ByteString
recvFromSock (sock, sockaddr) =  do 
    respLen <- S.recv sock (4 :: Int64
    let parsedLen = getLength respLen
    req <- recvExactly sock parsedLength 
    where
        getLength = runGet $ fromIntegral <$> getWord32be
\end{lstlisting}

After getting the size of a particular request, this determined amount of bytes
is received from socket. Because of the blocking semantics of unix sockets and
tcp packet fragmentation it is not guaranteed, that the len argument to the recv
system call gets the exactly number of bytes of the whole request. The call may produce
less data than specified. Therefore we implement the following function to get
the data in
chunks until the entire request is read. 

\begin{lstlisting}
recvExactly :: Socket -> Int64 -> IO BL.ByteString 
recvExactly sock size = BL.concat . reverse <$> loop [] 0 
  where
    loop chunks bytesRead
        | bytesRead >= size = return chunks
        | otherwise = do  
            chunk <- S.recv sock (size - bytesRead)
            if BL.null chunk 
              then return chunks 
              else loop (chunk:chunks) $! bytesRead + BL.length chunk 
\end{lstlisting}

\subsection{Send data}
\label{sec:impl-broker-socket-send}
For every processed request an appropriate response is sent back to the client.
The actual message is already provided as binary data from the API layer. The
network layer simply needs to send the bytes over the existing connection back
to the client. For sending data over socket function sendAll from \fnurl{Network.Socket.ByteString.Lazy}
{https://hackage.haskell.org/package/network-2.3.0.1/docs/Network-Socket-ByteString-Lazy.html}
is used. This function continues to send data until either all
data has been sent or an error occurs. For further details about the Error Handling, see section \ref{}

\begin{lstlisting}
import qualified Data.ByteString.Lazy as B
import qualified Network.Socket.ByteString.Lazy as S

sendResponse :: (Socket, SockAddr) -> B.ByteString -> IO (Either IOError ())
sendResponse (socket, addr) responsemessage = 
             try(S.sendAll socket responsemessage) :: IO (Either IOError ())
\end{lstlisting}

\section{API Layer}
\label{sec:broker-api}
The API layer covers the following actions: 
\begin{enumerate}
    \item Decode Request
    \item Handle Request
    \item Encode Response
\end{enumerate}

Whereas the parts of decoding a requests and encoding a responses simply uses functions
provided by the protocol implementation (see chapter \ref{sec-protocol}), the
main focus of the API layer lies on handling the requests properly. 

\subsection{Handle Request}
\label{sec:impl-broker-api-handle}
Depending on the API key field of type RequestMessage, the request handler
determines the appropriate action. In case of an unkown API key, a handleError
and otherwise a builded ResponseMessage (ByteString) ist given. 

\begin{lstlisting}
handleRequest :: RequestMessage -> IO (Either HandleError BL.ByteString)
handleRequest rm = do
   handle <- case rqApiKey rm of
    0  -> handleProduceRequest (rqRequest rm)
    1  -> handleFetchRequest (rqRequest rm)
    2  -> handleOffsetRequest (rqRequest rm)
    3  -> handleMetadataRequest (rqRequest rm)
    8  -> handleOffsetCommitRequest (rqRequest rm)
    9  -> handleOffsetFetchRequest (rqRequest rm)
    10 -> handleConsumerMetadataRequest (rqRequest rm)
    _  -> return (Left UnknownRqError)
   return handle
\end{lstlisting}

\subsubsection{HandleProduceRequest}

\subsubsection{HandleFetchRequest}

\subsubsection{HandleMetadataRequest}

\section{Error Handling}
\label{sec:broker-error-handling}

A message broker relies fundamentally on error handling has to be discussed very
serious as fault tolerance and reliability are key requirements \todo{ref:
relieablility in messaging section} of such a system. The first part of this
section concentrates on the architectural details and decisions being made
regarding the error handling. Using a demonstration of a message flow, possible
edge cases they have to be considered will be uncovered in order to provide
reliability to the user of this broker. The second part covers the techniques
being used in Haskell to handle the previously described concept and cases where
errors may occur. This will also involve part of the concept behind the error
handling of Apache Kafka -- which is partly integrated in the Apache Kafka
Protocol and thus adapted in this implementation.

\subsection{Message flow}

The figure (\ref{fig:broker-error-activity}) provides insight in the process an
incoming request message goes through. As for simplicity, one may think of one
message being proceeded through all steps successively -- while in fact,
multiple requests are handled at the same time. Assuming the connection to the
broker is established and the client is ready to send requests to the broker,
there are principally two types of errors may occur and for each of which there
is a separate handler to handle error appropriately.

\begin{figure}[H]
  \centering
  \resizebox {0.7\linewidth} {!} {
    \input{broker_activiy.tex}
  }
  \caption{Broker error handling concept}
  \label{fig:broker-error-activity}
\end{figure}

\subsubsection{Socket Error}

During the process of listening to an open connection and reading incoming
byte-stream, as described in \ref{sec:broker-network}, there is a chance that
unexpected errors occur. The underlying C socket implementation will in this
case return a result of \textit{-1} which will result in an
\fnurl{IOError}{https://hackage.haskell.org/package/base-4.4.1.0/docs/System-IO-Error.html}. 

Errors at this stage will be handled using the \textit{Socket Error Handler} and
do not result in any response to the client who has initiated the request that
result in an error as the socket connection may be broken. Instead, the error is
simply caught and can then be reported using a separate logging framework such
as \fnurl{hslogger}{https://hackage.haskell.org/package/hslogger}. At worst, the
socket connection has to be closed.

\subsubsection{Request Error}

One step further, in the API-Stage (\ref{sec:broker-api}) where socket errors
may occur has been passed, the heavy part of error handling has began. Each step
the request passes may result in an error. To name a few, this can be the case
starting by parsing the request, by writing data to the disk executed by the log
subsystem, or even by producing the response message at last. All of the
mentioned cases and those who fell into the related category, will be handled by
the \textit{RequestErrorHandler} where a set of possible errors or category of
error is defined and will result in an appropriate response message which will
be sent to the client.


\subsection{Defining Error Types}

The previously introduced concept of the two error handlers, each responsible
for a certain layer of the application, can be built in Haskell very
conveniently by using the \fnurl{Either
Monad}{https://hackage.haskell.org/package/category-extras-0.52.0/docs/Control-Monad-Either.html}
and pattern matching of custom defined error types. This will allow to take
actions based on the given error type.  

Error types related to the networking layer are simply distinguished between an
error occurred either in the receiving or responding process.

\begin{code}
data SocketError =
      SocketRecvError String
      | SocketSendError String
      deriving Show
\end{code}

Any further details are not separated by sub-types but instead, can be described
in the first argument of the \lstinline{SocketError}, namely a
\lstinline{String}.

To handle errors during the process of request handling, the data type
\lstinline{HandleError} contains specific types for each edge case in any part
of the application. Those types can be considered as an interface for errors
between the request handler and the underlying subsystems. They are not known to
any subsystem at all, but are known to the request handler.

\begin{code}
data HandleError =
        PrWriteLogError Int String
      | PrPackError String
      | ParseRequestError String
      | FtReadLogError Int String
      | SendResponseError String
      | UnknownRqError
        deriving Show
\end{code}


\subsection{Error Handlers}

With the knowledge about the types they are related to either socket- or request
errors it is now possible to create handler functions, they act as a central
place where any kind of error can be sent to and will provide the
functionality to handle appropriately. The figure
\ref{fig:broker-error-activity-detail} illustrates that the two
mentioned error handlers distinguish their next action based on the data type,
containing its arguments, that is sent to the error handler.

\begin{figure}[H]
  \centering
  \resizebox {0.7\linewidth} {!} {
    \input{broker_activiy_extended.tex}
  }
  \caption{Broker error handling concept in detail}
  \label{fig:broker-error-activity-detail}
\end{figure}

Assuming during the process of an incoming \lstinline{ProduceRequest}, the log
subsystem fails to write data to the disk and returns a log specific error. This
error will not be handled directly, but instead be caught by the request handler
(API layer) who is now in charge to map this error to one of the defined
\lstinline{HandleError}. In this specific example, the request handler would
then take the error response from the log system, map it to a \lstinline{String}
if not already is, as well as the offset of the failing message and assign this
information to the type \lstinline{PrWriteLogError} as the first and second
argument. \\

The following part of this section will describe the functionalites of the
\textit{Socket Error Handler} as well as the \textit{Request Error Handler}
provided by the functions \lstinline{handleSocketError} and
\lstinline{handleHandlerError}.

\subsubsection{Socket Error Handler}

The scope of handling a socket related error is very limited due to the fact
that the connection may be broken or the client will not receive any more data
using the current connection. Given this, the current implementation does only
print the occurred error on console:

\begin{code}
handleSocketError :: (Socket, SockAddr) -> SocketError -> IO()
handleSocketError (sock, sockaddr) (SocketRecvError e) = do
  putStrLn $ "[Socket Receive Error] " ++ e
handleSocketError (sock, sockaddr) (SocketSendError e) = do
  putStrLn $ "[Socket Send Error] " ++ e
\end{code}

While further logging of errors is out of scope within this thesis, the given
architecture may very well be able to do so. At the point after the pattern
matched, and currently is only a \lstinline{putStrLn} implemented, one
could inject an external logging service providing more meaningful information
such as proposed in \fnurl{RFC5424}{http://tools.ietf.org/html/rfc5424}.

\subsubsection{Request Error Handler}

The Apache Kafka Protocol specifies especially
defines error codes (see \ref{subsec:protocol-types-error-codes}) which should
be applied to a response message if the given failed for some reason. Thus, the
\lstinline{handleHandlerError} function is responsible to provide the related
response message containing the appropriate error code. However, the current
implementation does not suppport response message caused by an error but instead
does print a notification on broker side as shown in the code below:

\begin{code}
handleHandlerError :: (Socket, SockAddr) -> HandleError -> IO()
handleHandlerError (s, a) (ParseRequestError e) = do
    putStrLn $ (show "[ParseError]: ") ++ e
    putStrLn $ "***Host " ++ (show a) ++ " disconnected ***"
handleHandlerError (s, a) (PrWriteLogError o e) = do
    putStrLn $ show "[WriteLogError on offset " ++ show o ++ "]: " ++ show e
handleHandlerError (s, a) UnknownRqError = do
    putStrLn $ show "[UnknownRqError]"
handleHandlerError (s, a) e = do
    putStrLn $ show e
    S.sendAll s $ C.pack $ show e
    sClose s
    putStrLn $ "***Host " ++ (show a) ++ "disconnected ***"
\end{code}


\section{Threading}
\label{sec:impl-broker-threading}
The threading concept of the broker server application include the following
instances: 

\begin{description}
\item[Acceptor Thread (one instance)] \hfill \\
    This thread accepts new socket connections (see
    \ref{sec:impl-broker-socket-connection}). To support multiple connections from
    different clients the it forks a new thread for processing incoming data
    whenever a new connection is established. 

\item[Connection Processor Thread (one instance per connection)] \hfill \\
    The incoming socket data need to be processed as fast as possible because if the
    limit of the socket buffer is reached, the throughput on the network drops
    dramatically. The processor thread constantly receives request
    from a specific connection (see \ref{sec:impl-broker-socket-receive}) and
    provide it to the API handler thread. If the connection is closed the
    thread will return. 

\item[Responder Thread (one instance per connection)] \hfill \\
    This thread works off the provided responses and sends them back to the original
    client (see \ref{sec:impl-broker-socket-send}). \todo{actually only one
    instance at the moment} \item [API Handler Thread (one to N instances)] \hfill
    \\
    The API handler is a worker thread which just works off the received request . It
    also build appropriate responses and provide it to the responder thread
    (see \ref{sec:impl-broker-api-handle}). It is conceivable to run more than
    one instances of the API handler. Due to advanced synchronisation this is
    not realized yet.
\item [Main Thread (one instance)] \hfill \\
    The main function of the broker bootstraps the whole server application. It first
    initializes the network socket and forks the acceptor and API
    handler threads. Threads are managed due the \textit{withAsync} function of
    the \fnurl{Control.Concurrent.Async}
    {https://hackage.haskell.org/package/async-2.0.0.0/docs/Control-Concurrent-Async.html}
    library. It adds a thin layer over the basic concurrency operations provided
    by \fnurl{Control.Concurrent}
    {https://hackage.haskell.org/package/base-4.5.0.0/docs/Control-Concurrent.html}
    and gives the ability to wait for the return value of a thread. This
    provides additional safety and control if a threads gets crashed. 
\end{description}

Original Apache Kafka has a fix and configurable amount of threads
handling network request by working with thread pools. Thanks to the
optimizations of the GHC IO manager, the communication with the haskell threads
and the OS is very efficient due to thread multiplexing. Thread pooling has no
further advantages than one socket processor thread instance per connection. 

For transfer of data between the threads, channels are implemented. The \fnurl{Control.Concurrent.Chan}
{http://hackage.haskell.org/package/base-4.8.0.0/docs/Control-Concurrent-Chan.html}
package provides a one-way FIFO communication channel. This concept
is being used to separate the three layers from each other. The
fact that \textit{chan} is unbounded brings a risk. While \textit{writeChan} --
which is being used to write to a channel -- succeeds immediately, there is a
chance that the consuming thread is not able to read the same amount of data in
a given time and thus the channel will grow in an unchecked manner.
\cite{o2008real}

To isolate the network layer from any build or parse process, the transfered
data is type ByteString. Because the response to a particular request need to be
sent back over the right connection, every chunk of ByteString holds its corresponding
socket connection information in a tuple:

\begin{lstlisting}
import qualified Data.ByteString.Lazy as B

type ChanMessage = ((Socket, SockAddr), B.ByteString)
type RequestChan = Chan ChanMessage
type ResponseChan = Chan ChanMessage
\end{lstlisting}

TODO: sanctions? do we have to block the producer for a short time? ->
Considerations Bounded Chans

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{images/impl-brok-threading.png}
    \caption{Threading concept which channeling}
    \label{fig:impl-brok-threading}
\end{figure}

\section{Log}

\subsection{Storage Layout}
\label{log-broker-storage}

The storage layout is exactly the same as the one defined for Apache Kafka (see
\ref{intro-kafka-log}).  As for now, the root location of the log is not
configurable and set to the folder named \textbf{./log} within the installation
directory of the broker. Each folder represents a partition of a specific topic
whereas the name of the folder is a combination of the topic name and the
partition number. 

There are two types of files they reside within the folder that specifies the
topic and partition (see folder structure):

\begin{description}
    \item[.index] Containing a sequence of index entries
    \item[.log] Containing a sequence of log entries
\end{description}

Both of the file types hold the same name which stays for the base offset and
can be considered as an unique identifier representing a 64 bit integer as a 20
character file name. As it was defined for Apache Kafka, the \textbf{base
offset} is the offset of the first log entry. For example if a log holds
messages whereas the first message has the offset \textit{5 :: Int64} the file
name of this log will be \textit{00000000000000000005.log} and the related
index file \textit{00000000000000000005.index}.

Using this naming convention and by
viewing multiple log files one can extract information about what range of
messages reside in which log. This is a very efficient way to perform a lookup
which is needed for example to append new log messages or archive old messages.

For example the topics named \textit{TopicA, TopicB and TopicC} with the
partitions \textit{0} and \textit{1}:

\begin{verbatim}
log
|
+--TopicA_0
   |--00000000000000000000.index
   |--00000000000000000000.log
   |--00000000000008650021.index
   |--00000000000008650021.log
+--TopicA_1
   |--00000000000000000000.index
   |--00000000000000000000.log
+--TopicB_0
   |--00000000000000000000.index
   |--00000000000000000000.log
   |--000000000000128655021.index
   |--000000000000128655021.log
+--TopicB_1
   |--00000000000000000000.index
   |--00000000000000000000.log
+--TopicC_0
   |--00000000000000000000.index
   |--00000000000000000000.log
\end{verbatim}

\subsection{On-disk format}

\subsubsection{Index entry}

The structure of an entry within the index file describes only 2 fields, each of
them 32 bit long:

\begin{itemize}
    \item 4 Bytes: Offset, relative to the base offset (file name)
    \item 4 Bytes: Physical Position, relative to the beginning of the log file
\end{itemize}

The relative offset of an index entry added with it's base offset represents an
actual message within the log. The second information, the physical position
then tells on what position the message resides within the log.

\subsubsection{Log entry}

The log contains a sequence of log entries whereas the on-disk format of a log
entry is is part of the reason why the Apache Kafka becomes that valuable. In
fact, the on-disk format is exactly the same as the format of the MessageSet
(see \ref{impl-protocol-types-data}) transmitted with a ProduceRequest
\todo{add requests to protocol and link this}. Thus, data does not have to be
modified in any way and can directly be extracted and written to the file
system.


\subsection{Index}

Every segment of a log has it's corresponding index, represented as a file with
the suffix \textit{.index}. Both the log and the index file hold the same name
name as it represents the base offset.

Whereas the log file contains the actual messages structured in a
message format and for each message within this file, the first 64 bits describe
the incremented offset. Now, looking up this file for messages with a specific
offset becomes very expensive since log files may grow in the range of gigabytes.
And to be able to produce messages, the broker actually has to do such kind of
lookups to determine the latest offset and be able to further increment
incoming messages correctly. This is why there is an index.

As described before, the file name represents the base offset. In contrast to
the log, where the offset is incremented for each message, the messages within
the index contain an offset relative to the base offset. The second field
represents the physical position of the related log message. Compare to a log
message, this can be considered as very small. In addition, there is to note
that not every message within the log is going to be indexed. By default, an
index entry is created only after \textbf{4096 Bytes} of log data.

\subsubsection{Lookup}

As per protocol specification, the request to fetch messages (see
\ref{subsubsec:protocol-fetchrequest}) holds the offset of the wanted message.
Given this offset, one can determine the base offset and is discussed later on
in the log section (see \ref{subsubsec:broker-log-general-baseoffset}).
Assuming to have a valid base offset as well as the actual offset of the wanted
message, it is not a big deal to figure out the relative offset of this
message:

\begin{verbatim}
Relative Offset = Offset - Base Offset
\end{verbatim}

Given the relative offset, a lookup over the log can be processed. Remembering
that the index is significantly smaller than the log and relies in memory, this
lookup becomes reasonably fast. In fact, the file system will proceed a binary
search and thus results in time complexity of O(log \textit{n}), where
\textit{n} is the number of index entries.

A successful lookup will then bring the information of the physical position of
closest message to wanted message within the log -- and this is valuable. While
the interval of index creation is fixed at a certain amount of bytes, a lookup
of the actual log message, given the position of the closest indexed message
will result in time complexity of O(1).

\subsection{Types}

\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|}
\hline
\textbf{Type synonym} & \textbf{Parameter}           & \textbf{Description}                     \\ \hline
TopicStr              & String                       & Parsed topic name as String              \\ \hline
PartitionNr           & Int                          & Parsed partition number as Int           \\ \hline
FilemessageSet        & {[}MessageSet{]}             &                                          \\ \hline
OffsetIndex           & {[}OffsetPosition{]}         &                                          \\ \hline
LogSegment            & (Log, OffsetIndex)           &                                          \\ \hline
RelativeOffset        & Word32                       & 4 Byte offset relative to the BaseOffset \\ \hline
FileOffset            & Word32                       & 4 Byte physical offset of a Log file     \\ \hline
OffsetPosition        & (RelativeOffset, FileOffset) & Tuple of relative and physical offset    \\ \hline
BaseOffset            & Int                          & 8 Byte offset as Int                     \\ \hline
\end{tabular}
}
\end{table}

\subsection{General functionality}

\subsubsection{Determine Base Offset}
\label{subsubsec:broker-log-general-baseoffset}

An incoming request -- which is at this point already parsed -- contains the
topic as well as the partition number for the given set of messages. Thus,
enough information is provided to identify the location -- in this case the path
-- of the related log file.  The thing that is still missing now, is either in
which file the messages should be appended (in case of a produce request) or
from which file the messages should be read from (in case of a fetch request).

In case of producing messages, the wanted file is the one named after the
highest offset. To be able to determine existing files, followed by string
transformations to identify the file with the highest number. This is why one
does not get around reading the content of this directory. Handling the case
where no file exists leads to the creation of a new log with the offset of zero.

\begin{lstlisting}
maxOffset :: [Int] -> Int
maxOffset [] = 0
maxOffset [x] = x
maxOffset xs = maximum xs
\end{lstlisting}

In case of receiving messages, the process is almost the same. The only
difference is, that the wanted file does not hold the highest offset but the one
that hold the offset which is the next smaller regarding the provided offset
number within a fetch request. Let's assume one wants to fetch the message with
offset \textit{400} and yet there are two different pairs of log- and index
files: \textit{100}, \textit{300}. The correct one would be \textit{300} as the
message must reside within this file.

\begin{lstlisting}
%todo: code for next smaller
nextSmaller :: [Int] -> Int -> Int
nextSmaller [] _ = 0
nextSmaller [x] _ = x
nextSmaller xs x = last $ filter (<x) $ sort xs
\end{lstlisting}

Before applying filters and string transformations, the list of files has to be
build. The library
\fnurl{System.Directory}{http://hackage.haskell.org/package/directory-1.2.2.1/docs/System-Directory.html}
provides the function \textit{getDirectoryContents} that takes a file path as a
string and returns a list of all entires in the directory. This operation
performs I/O and thus the return type is an IO monadic value. \textit{As
described on
\fnurl{hackage}{http://hackage.haskell.org/package/directory-1.2.2.1/docs/System-Directory.html\#v:getDirectoryContents},
there are several causes why this operation may fail but at this point, we do
not provide proper error handling.}
The function \textit{offsetFromFileName} can be mapped over a filtered list of
strings, which will give the list of all offsets within the directory. The
filter function basically omits the files other than the ones ending with
\textit{".log"} as well as the root directories, typically \textit{".", ".."}.

\begin{lstlisting}
getBaseOffsets :: (TopicStr, Int) -> IO [BaseOffset]
getBaseOffsets (t, p) = do
dirs <- getDirectoryContents $ getLogFolder (t, p)
return $ map (offsetFromFileName) (filter (isLogFile) (filterRootDir dirs))
\end{lstlisting}

As hinted in the code above, a filter function is being used to get the list of
all offsets within the directory. The function \textit{offsetFromFileName}
extracts the offset as an \textit{Int} from a \textit{String}. As an example,
\textit{"00000000000000000005.log" :: String } will be transformed to
\textit{0000000000000000005 :: Int}:

\begin{lstlisting}
offsetFromFileName :: [Char] -> Int
offsetFromFileName = read . reverse . snd . splitAt 4 . reverse
\end{lstlisting}

Finally, the \lstinline{Maybe Offset} helps to distinguish between the highest offset
(\lstinline{Nothing}) or the next smaller \lstinline{BaseOffset} related to a provided
\lstinline{Just Offset}. 

\begin{lstlisting}
getLastBaseOffset :: (TopicStr, Int) -> Maybe Offset -> IO BaseOffset
getLastBaseOffset (t, p) o = do
bos <- getBaseOffsets (t, p)
  case o of
    Nothing -> return (maxOffset bos)
    Just o  -> return (nextSmaller bos o)
\end{lstlisting}

\subsection{Write a log}

Writing data, type of MessageSet \todo{ref to type}, to a log is the
fundamental process behind the scenes of handling a ProduceRequest \todo{ref
to request}. But before actually writing data to the file system, several
steps come in between and will contribute significantly to the concept of
Apache Kafka's Log system \todo{ref to kafka log}. This section describes
the implementation details of the mentioned steps in the order of occurrence.



\subsubsection{Last Offset Position}

Given the highest offset for a specific topic name and partition, the next step
leads to determine the latest entry of the index file -- which is named after
this offset. The index file now will be parsed with the regard to identify the
latest offset and physical position of the message that lies within the actual
log file. In order to increase I/O performance the index file will be mapped
into memory first using
\fnurl{mmap}{http://man7.org/linux/man-pages/man2/mmap.2.html}. The resulting
memory-mapped file implements demand paging which is an operation that copies a
disk page into physical memory only if an attempt is made to access it or the
page is not already in memory. This comes very handy in terms of Haskell's
laziness such as that a lazy ByteString can be taken as a result of this
operation and thus memory consumption can be considered as moderate. But even
more importantly, the amount of I/O operations will be decreased drastically
for multiple lookups on the index file.

Haskell provides the System.IO.MMap library which is an interface to mmap(2)
system call under POSIX. 

%todo ...DESCRIBE MMAP LIBRARY...

\begin{lstlisting}
getLastOffsetPosition :: (TopicStr, Int) -> BaseOffset -> IO OffsetPosition
getLastOffsetPosition (t, p) bo = do 
  let path = getPath (getLogFolder (t, p)) (indexFile bo)
  -- check if file exists
  bs <- mmapFileByteStringLazy path Nothing
  case decodeIndex bs of
    Left (bs, bo, e)   -> do
        print e
        return (0,0)
    Right (bs, bo, ops) -> return (lastIndex ops)
\end{lstlisting}

%todo describe decodeIndex

\subsubsection{Last Log Offset}

The last offset provided by the index file does not ensure that this is the
last offset above all existing messages within the log. As described in the
storage section (\ref{log-broker-storage}), index entries are created only after a
certain amount of bytes has been passed. The gap between the last offset of the
index and the last offset of the log will be resolved by parsing the messages
between the two offsets where the last of those messages can finally be
considered as the message that contains the highest offset above all messages. 

Fortunately, the mmap wrapper function \textit{mmapFileByteStringLazy} takes a
\textit{Maybe (Int64, Int64)} to specify the range of the file to be mapped.
The range is defined by the offset, which is the beginning byte of the file
region and the size tells the mapping length.

\begin{lstlisting}
getLastLogOffset :: (TopicStr, Int) -> BaseOffset -> OffsetPosition -> IO Offset
getLastLogOffset (t, p) bo (rel, phys) = do
  let path = getPath (logFolder t p) (logFile bo)
  fs <- getFileSize path
  bs <- mmapFileByteStringLazy path $ Just (fromIntegral phys, (fromIntegral (fs) - fromIntegral phys))
  return (lastOffset $ runGet getLog bs)
\end{lstlisting}

\subsubsection{Append Index}

\subsubsection{Append Log}


\subsection{Read from log}
A consumer client which request messages from broker via FetchRequest, actually

\subsection{Optimization}

Next to optimizations like batching in the network layer \todo{ref to network},
we do also provide some optimizations in terms of I/O. \todo{Kafka: a
Distributed Messaging System for Log Processing}.

\subsubsection{Page Cache:}

First of all, We therefore avoid to explicitly cache messages in memory but
instead rely on the underlying file system cache. This has the benefit of
avoiding double buffering since messages are only cached in the page cache.
Thus, even if the broker process has to be restarted, the cache retains warm.

\todo{more details on modern os and page cache}

\subsubsection{Sequential I/O: }

While producers and consumers lead the broker to access
segments of files, the actual access which taking place is going to be a
sequential access rather than random. This will reduce seeking time to 1 per
partition. In fact, the broker holds a point on a given offset whereas all
messages below the pointer can be considered as already consumed and all
messages with offset greater than the provided one as unconsumed. Now since
messages are ordered this will lead to a sequential I/O with a constant seeking
time (O(1)).


\subsubsection{Internal data transfer:}

As mentioned earlier, HMB omit explicit caching but instead relies on the file system.
Keep this in mind, the actual network access for consumers can be optimized as well.
While a typical approach to sending bytes from a local file to a remote
socket involves the following steps: 
\begin{enumerate}
  \item Read data from storage (disk)
  \item Copy data from the page cache to an application buffer
  \item Copy application buffer to a kernel buffer
  \item Send kernel buffer to the socket
\end{enumerate}

With the help of the sendfile API \todo{ref} it is possible to transfer bytes
from a file channel to a socket channel, whereas the delivery process will
result in the following steps:

\begin{enumerate}
  \item Read data from storage (disk)
  \item Send data from page cache to the socket
\end{enumerate}

\section{Testing}
hspec 

\section{Client Examples}
This example shows a very basic console client which either can act as producer
by sending a producer request or as a consumer by sending a fetch request. After
sending the client wait for a corresponding response from the broker.

Init stream socket an open connection to a given host address and port (broker must be running on same ip and port): 
\begin{lstlisting}
  sock <- socket AF_INET Stream defaultProtocol 
  setSocketOption sock ReuseAddr 1
  putStrLn "Give IP"
  ipInput <- getLine
  let ip = toHostAddress (read ipInput :: IPv4)
  putStrLn "Give Port"
  port <- getLine
  connect sock (SockAddrInet port ip)
\end{lstlisting}
\todo{port convertierung}

If connection succeeded give client id and topic name: 
\begin{lstlisting}
  putStrLn "Give Client Id"
  clientId <- getLine
  putStrLn "Give Topic Name"
  topicName <- getLine
\end{lstlisting}

Producer: Sends given message to the broker. Client API function packPrRqMessage
packs the input into a protocol conform produce request, whereas the function
sendRequest encodes the request an send it over given socket connection.
Afterwards a response from broker is expected. If there is a response the client
can decode it with the API function decodePrResponse. 
\begin{lstlisting}
  forever $  do 
    putStrLn "Nachricht eingeben"
    inputMessage <- getLine
    sendRequest sock $ packPrRqMessage (clientId, topicName, 0, inputMessage)

    input <- recv sock 4096
    let response = decodePrResponse input
    print response 
\end{lstlisting}

Consumer: Send a fetch request with given offset to the broker. Analog to the producer request 
the api function packFtRqMessage packs the input into a protocol conform fetch request and sendRequest passes it via socket to the broker. 
\todo{code not final yet}


