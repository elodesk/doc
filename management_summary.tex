\chapter{Management Summary}

\section{Introduction}

Nowadays one can speak as of a fundamental change in web systems. Internet companies
created a need for activity data, in a volume, which has never been existed before.
And the trends holds on -- not only companies with its core business in the cloud are
depending on this amount of data, more and more companies with a more traditional 
fashioned core business are tending to depend on an amount of data, which will sooner
or later sourmount the yet so overwelming data volumes of the big five (Facebook, Twitter, Google, LinkedIn, Airbnb).

%NOTES:
%One trend in the implementation of modern web systems is the use of activity data in the form of log or
%event messages that capture user and server activity. This data is at the heart of many internet systems in
%the domains of advertising, relevance, search, recommendation systems, and security, as well as contin-
%uing to fulfill its traditional role in analytics and reporting. Many of these uses place real-time demands
%on data feeds. Activity data is extremely high volume and real-time pipelines present new design chal-
%lenges. This paper discusses the design and engineering problems we encountered in moving LinkedInâ€™s
%data pipeline from a batch-oriented file aggregation mechanism to a real-time publish-subscribe system
%called Kafka.
%
%- big data companies and their needs
%- linkedin with kafka
%- same approach in haskell with functional benefits and lightweigth
%parallellization
%- 

\section{Approach and Technologies}

\section{Results}

\section{Outlook}
(optional)
